{
    "last_updated": "2025-03-22T13:01:05.449887",
    "posts": [
        {
            "title": "How Inconvo is improving customer-facing analytics with conversational AI built on LangGraph",
            "source": "LangChain",
            "url": "https://blog.langchain.dev/customers-inconvo/",
            "published": "Wed, 19 Mar 2025 18:41:17 GMT",
            "summary": "See how Inconvo leverages LangGraph to empower non-technical users to conduct data analysis seamlessly through natural language queries.",
            "tags": [
                "LangChain"
            ]
        },
        {
            "title": "AI Policy: ü§ó Response to the White House AI Action Plan RFI",
            "source": "Hugging Face",
            "url": "https://huggingface.co/blog/ai-action-wh-2025",
            "published": "Wed, 19 Mar 2025 00:00:00 GMT",
            "summary": "No summary available.",
            "tags": [
                "HuggingFace"
            ]
        },
        {
            "title": "7 retail trends to watch this year from NRF 2025: Retail‚Äôs Big Show",
            "source": "Microsoft AI",
            "url": "https://www.microsoft.com/en-us/industry/blog/retail/2025/03/12/7-retail-trends-to-watch-this-year-from-nrf-2025-retails-big-show/",
            "published": "Wed, 12 Mar 2025 19:00:00 +0000",
            "summary": "<p>From AI innovations to Gen Zalpha as consumer, this year‚Äôs NRF Big Show brought fresh perspectives on how technology and human interaction are redefining the industry.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/industry/blog/retail/2025/03/12/7-retail-trends-to-watch-this-year-from-nrf-2025-retails-big-show/\">7 retail trends to watch this year from NRF 2025: Retail‚Äôs Big Show</a> appeared first on <a href=\"https://www.microsoft.com/en-us/ai/blog\">Microsoft AI Blogs</a>.</p>",
            "tags": [
                "Microsoft"
            ]
        },
        {
            "title": "Gemini Robotics brings AI into the physical world",
            "source": "DeepMind",
            "url": "https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/",
            "published": "Wed, 12 Mar 2025 15:00:00 +0000",
            "summary": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
            "tags": [
                "DeepMind"
            ]
        },
        {
            "title": "Experiment with Gemini 2.0 Flash native image generation",
            "source": "DeepMind",
            "url": "https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/",
            "published": "Wed, 12 Mar 2025 14:58:00 +0000",
            "summary": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
            "tags": [
                "DeepMind"
            ]
        },
        {
            "title": "Introducing Gemma 3",
            "source": "DeepMind",
            "url": "https://deepmind.google/discover/blog/introducing-gemma-3/",
            "published": "Wed, 12 Mar 2025 08:00:00 +0000",
            "summary": "The most capable model you can run on a single GPU or TPU.",
            "tags": [
                "DeepMind"
            ]
        },
        {
            "title": "How Build.inc used LangGraph to launch a Multi-Agent Architecture for automating critical CRE workflows for Data Center Development.",
            "source": "LangChain",
            "url": "https://blog.langchain.dev/how-build-inc-used-langgraph-to-launch-a-multi-agent-architecture-for-automating-critical-cre-workflows-for-data-center-development/",
            "published": "Wed, 05 Mar 2025 15:00:21 GMT",
            "summary": "<p><em>Editor&apos;s note: This is a guest blog post from our friends at </em><a href=\"https://build.inc/?ref=blog.langchain.dev\"><em>Build.inc</em></a><em>. They built one of the more complex multi-agent workflows we&apos;ve seen - with over 25 sub agents. Check out the screenshot of their graph for an idea of the complexity. They also</em></p>",
            "tags": [
                "LangChain"
            ]
        },
        {
            "title": "Gemini 2.0 is now available to everyone",
            "source": "DeepMind",
            "url": "https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/",
            "published": "Wed, 05 Feb 2025 16:00:00 +0000",
            "summary": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
            "tags": [
                "DeepMind"
            ]
        },
        {
            "title": "Start building with Gemini 2.0 Flash and Flash-Lite",
            "source": "DeepMind",
            "url": "https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/",
            "published": "Tue, 25 Feb 2025 18:02:12 +0000",
            "summary": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
            "tags": [
                "DeepMind"
            ]
        },
        {
            "title": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
            "source": "Hugging Face",
            "url": "https://huggingface.co/blog/nvidia-physical-ai",
            "published": "Tue, 18 Mar 2025 00:00:00 GMT",
            "summary": "No summary available.",
            "tags": [
                "HuggingFace"
            ]
        },
        {
            "title": "Xet is on the Hub",
            "source": "Hugging Face",
            "url": "https://huggingface.co/blog/xet-on-the-hub",
            "published": "Tue, 18 Mar 2025 00:00:00 GMT",
            "summary": "No summary available.",
            "tags": [
                "HuggingFace"
            ]
        },
        {
            "title": "LlamaIndex Newsletter 2025-03-18",
            "source": "LlamaIndex",
            "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2025-03-18",
            "published": "Tue, 18 Mar 2025 00:00:00 GMT",
            "summary": "<p><strong>Hi there, Llama Lovers! ü¶ô</strong></p><p>Welcome to this week&#x27;s edition of the LlamaIndex newsletter! We&#x27;re thrilled to share some exciting updates, including the launch of LlamaExtract in public beta, a step-by-step tutorial on building agentic reasoning systems, and a collection of templates for automating knowledge work. Dive into these highlights and more to enhance your experience with our tools!</p><p><strong>ü§© The Highlights:</strong></p><ul><li><strong>Step-by-Step Tutorial on Corrective RAG:</strong> Check out this fantastic tutorial by @akshay_pachaar on building an agentic reasoning system for search and retrieval (specifically, corrective RAG) from scratch using @llama_index workflows. <a href=\"https://t.co/XvggKSY4T9\" rel=\"noreferrer noopener\">Learn more</a>.</li><li><strong>Task-Specific Agent Templates:</strong> We‚Äôre curating a collection of templates that show you how to build task-specific agents to automate knowledge work. With just a few lines of code, you can orchestrate workflows for various tasks, including processing slide decks and extracting invoice line items. <a href=\"https://t.co/y29XYWXyHb\" rel=\"noreferrer noopener\">Explore the templates</a> and <a href=\"https://t.co/yQGTiRSfFL\" rel=\"noreferrer noopener\">sign up for LlamaCloud</a>.</li><li><strong>Model Context Protocol Integration:</strong> Connect your LlamaIndex agents to any Model Context Protocol server! This integration allows you to use tools exposed by any MCP-compatible server in your LlamaIndex agent with just one line of code. <a href=\"https://t.co/3hViiJkmEW\" rel=\"noreferrer noopener\">Install the integration</a> and <a href=\"https://t.co/KyIGhLVZkg\" rel=\"noreferrer noopener\">see a full demo</a>.</li></ul><p><strong>üó∫Ô∏è LlamaCloud &amp; LlamaParse:</strong></p><ul><li><strong>LlamaExtract Public Beta:</strong> LlamaExtract is now in public beta! This tool allows you to extract structured data from long, complex documents effortlessly. <a href=\"https://t.co/W4L6g6B2VA\" rel=\"noreferrer noopener\">Read the full post</a> and <a href=\"https://t.co/zqUqveKp6b\" rel=\"noreferrer noopener\">sign up for LlamaExtract</a>.</li></ul><p><strong>‚ú® Framework:</strong></p><ul><li><strong>Enhanced Workflows for LlamaIndex:</strong> We‚Äôre excited to announce updates that allow you to orchestrate complex, customizable event-driven agent workflows using @llama_index. This enhancement is crucial for building robust AI solutions. <a href=\"https://t.co/XvggKSY4T9\" rel=\"noreferrer noopener\">Check out the introduction to workflows</a>.</li></ul><p><strong>‚úçÔ∏è Community:</strong></p><ul><li><strong>AI and Web Development Insights:</strong> Join industry experts at @WeAreDevs WebDev &amp; AI Day on March 27 to learn about AI&#x27;s role in platform engineering and developer tools. <a href=\"https://t.co/jwNWlRUTZV\" rel=\"noreferrer noopener\">Learn more about the event</a> and get a 15% discount on us! <a href=\"https://t.co/N5Ogvl5E5Z\" rel=\"noreferrer noopener\">Claim your discount</a>.</li><li><strong>5th LLM x Law Hackathon:</strong> Participate in the upcoming hackathon at @stanford on April 6, where innovators will develop AI solutions for legal work. <a href=\"https://t.co/qEzhWgtRoZ\" rel=\"noreferrer noopener\">Sign up to participate</a>.</li><li><strong>Updated AnthropicAI Cookbook:</strong> We‚Äôve expanded our @AnthropicAI cookbook with new features, including basic API setup, streaming support, and multi-modal capabilities. <a href=\"https://t.co/rkRr4WaIOx\" rel=\"noreferrer noopener\">Check it out here</a>.</li><li><strong>Real-Time Knowledge Graph Exploration:</strong> Explore a knowledge graph in real-time using LLMs with the impressive demo from @yworks showcasing their SDK for visualizing knowledge graphs. <a href=\"https://t.co/5ARhE7jXVf\" rel=\"noreferrer noopener\">Read their blog</a> or head to the <a href=\"https://t.co/J4Z32uBZ3B\" rel=\"noreferrer noopener\">repo</a>.</li></ul><p>Thank you for being part of our community! Stay tuned for more updates, and don‚Äôt hesitate to reach out with any questions or feedback.</p>",
            "tags": [
                "LlamaIndex"
            ]
        },
        {
            "title": "Announcing the Responses API and Computer-Using Agent in Azure AI Foundry",
            "source": "Microsoft AI",
            "url": "https://azure.microsoft.com/en-us/blog/announcing-the-responses-api-and-computer-using-agent-in-azure-ai-foundry/",
            "published": "Tue, 11 Mar 2025 20:30:00 +0000",
            "summary": "<p>AI agents are transforming industries by automating workflows, enhancing productivity, and enabling intelligent decision-making. Businesses are leveraging AI agents to process insurance claims, manage IT service desks, optimize supply chain logistics, and even assist healthcare professionals in analyzing medical records. The potential is vast, and we‚Äôre excited to introduce two powerful innovations in Azure AI Foundry.</p>\n<p>The post <a href=\"https://azure.microsoft.com/en-us/blog/announcing-the-responses-api-and-computer-using-agent-in-azure-ai-foundry/\">Announcing the Responses API and Computer-Using Agent in Azure AI Foundry</a> appeared first on <a href=\"https://www.microsoft.com/en-us/ai/blog\">Microsoft AI Blogs</a>.</p>",
            "tags": [
                "Microsoft"
            ]
        },
        {
            "title": "4 keys to the future of public finance with Microsoft 365 Copilot for Finance",
            "source": "Microsoft AI",
            "url": "https://www.microsoft.com/en-us/industry/blog/government/2025/03/11/4-keys-to-the-future-of-public-finance-with-microsoft-365-copilot-for-finance/",
            "published": "Tue, 11 Mar 2025 16:00:00 +0000",
            "summary": "<p>Microsoft 365 Copilot for Finance (preview) is an AI-powered, role-based Copilot agent designed to help government agencies speed time to impact.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/industry/blog/government/2025/03/11/4-keys-to-the-future-of-public-finance-with-microsoft-365-copilot-for-finance/\">4 keys to the future of public finance with Microsoft 365 Copilot for Finance</a> appeared first on <a href=\"https://www.microsoft.com/en-us/ai/blog\">Microsoft AI Blogs</a>.</p>",
            "tags": [
                "Microsoft"
            ]
        },
        {
            "title": "LlamaIndex Newsletter 2025-03-11",
            "source": "LlamaIndex",
            "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2025-03-11",
            "published": "Tue, 11 Mar 2025 00:00:00 GMT",
            "summary": "<p>Hi there, Llama Peeps! ü¶ô</p><p>Welcome to this week&#x27;s edition of the LlamaIndex newsletter! It was a very big week for us last week, so have a ton to share!</p><p>ü§© <strong>The Highlights:</strong></p><ul><li><strong>LlamaCloud General Availability:</strong> In case you missed it: huge news! LlamaCloud is now available for everyone to sign up. It‚Äôs the core of our enterprise offering for agentic knowledge management over unstructured data. <a href=\"https://t.co/LwyimisQoj\" rel=\"noreferrer noopener\">Full announcement here!</a></li><li><strong>Series A:</strong> We also announced our $19M series A funding round! <a href=\"https://www.llamaindex.ai/blog/llamaindex-newsletter-2025-03-04\" rel=\"noreferrer noopener\">Hear from our investors</a>.</li><li><strong>Hugging Face Course on Building Agents:</strong> Our friends at HuggingFace have created a comprehensive course covering the components of LlamaIndex, RAG, tools, agents, and workflows. <a href=\"https://t.co/eACAJzXg8y\" rel=\"noreferrer noopener\">Check it out!</a></li><li><strong>DeepLearning Agentic Document Workflows Course:</strong> We‚Äôve partnered with DeepLearning.AI to offer a short course on integrating agentic workflows into your software processes. <a href=\"https://t.co/EvAKtIAzlC\" rel=\"noreferrer noopener\">Learn more here!</a></li></ul><p><strong>üó∫Ô∏è LlamaCloud &amp; LlamaParse:</strong></p><ul><li><strong>LlamaParse Updates:</strong> Our Parse With Agent mode now supports @AnthropicAI Claude Sonnet 3.7 and @google Gemini 2.0 Flash for better table parsing and cross-page consistency. <a href=\"https://t.co/yQGTiRSNvj\" rel=\"noreferrer noopener\">Sign up for LlamaParse!</a> | <a href=\"https://t.co/15neOxPsyY\" rel=\"noreferrer noopener\">Read more in our docs!</a></li><li><strong>Templates for Task-Specific Agents:</strong> We‚Äôre curating templates that help automate knowledge work with just a few lines of code. Explore how to process slide decks, extract invoice items, review contracts, and generate reports. <a href=\"https://t.co/y29XYWXyHb\" rel=\"noreferrer noopener\">View the repo!</a> | <a href=\"https://t.co/yQGTiRSfFL\" rel=\"noreferrer noopener\">Sign up for LlamaCloud!</a></li></ul><p><strong>‚ú® Framework:</strong></p><ul><li><strong>Multilingual, Multimodal RAG System:</strong> Learn how to build a powerful Retrieval-Augmented Generation system with LlamaIndex and Qdrant that handles multiple languages and modalities. <a href=\"https://t.co/69CHCCn8J3\" rel=\"noreferrer noopener\">Explore the guide!</a></li><li><strong>Updated Anthropic Cookbook:</strong> We‚Äôve expanded our cookbook to include API setup, streaming support, multi-modal capabilities, and more. <a href=\"https://t.co/rkRr4WaIOx\" rel=\"noreferrer noopener\">Check it out!</a></li></ul><p><strong>‚úçÔ∏è Community:</strong></p><ul><li><strong>Real-Time Knowledge Graph Exploration:</strong> Check out the demo from @yworks showcasing yFiles for visualizing knowledge graphs with real-time updates and interactions. <a href=\"https://t.co/5ARhE7jXVf\" rel=\"noreferrer noopener\">Read their blog!</a> | <a href=\"https://t.co/J4Z32uBZ3B\" rel=\"noreferrer noopener\">View the repo!</a></li><li><strong>Mistral OCR Benchmarking:</strong> RT @jerryjliu0 shares insights on Mistral OCR and its performance in document processing. <a href=\"https://t.co/ECHH1T4Kxn\" rel=\"noreferrer noopener\">Read more!</a></li><li><strong>Agentic Document Workflows Tutorial:</strong> A new course with @DeepLearningAI on building agentic document workflows is now available. <a href=\"https://t.co/EvAKtIAzlC\" rel=\"noreferrer noopener\">Learn more!</a></li><li><strong>Building a Workflow-Based Travel Planner:</strong> Follow RS Rohan&#x27;s tutorial on creating an advanced travel planner using @llama_index. <a href=\"https://t.co/4D48XuJQEM\" rel=\"noreferrer noopener\">Watch the tutorial video!</a> | <a href=\"https://t.co/B38vAixzz5\" rel=\"noreferrer noopener\">Access the full repo!</a></li><li><strong>Enhancing autism care:</strong> CentralReach has created an AI-enhanced Electronic Medical Record platform that helps doctors deliver care more effectively. <a href=\"https://www.gravity9.com/blog/enhancing-autism-care-ai-agent/\" rel=\"noreferrer noopener\">Read all about it</a></li></ul><p>Stay tuned for more updates, and as always, feel free to <a href=\"https://www.llamaindex.ai/contact\" rel=\"noreferrer noopener\">get in touch</a> with us for any questions or feedback!</p>",
            "tags": [
                "LlamaIndex"
            ]
        },
        {
            "title": "LlamaIndex Newsletter 2025-03-04",
            "source": "LlamaIndex",
            "url": "https://www.llamaindex.ai/blog/llamaindex-newsletter-2025-03-04",
            "published": "Tue, 04 Mar 2025 00:00:00 GMT",
            "summary": "<p>Hi there, Llama Fam! ü¶ô</p><p>Welcome to this week&#x27;s edition of the LlamaIndex newsletter! We have some exciting updates to share!</p><p>First and foremost: we&#x27;re delighted to announce that <a href=\"https://www.llamaindex.ai/blog/announcing-our-series-a-and-llamacloud-general-availability\" rel=\"noreferrer noopener\">LlamaCloud is now generally available</a>! No more waitlists: anyone can <a href=\"https://cloud.llamaindex.ai/\" rel=\"noreferrer noopener\">sign up today</a>.</p><p>Also happening today: we&#x27;re announcing that we have raised a <a href=\"https://www.llamaindex.ai/blog/announcing-our-series-a-and-llamacloud-general-availability\" rel=\"noreferrer noopener\">$19M series A funding round</a> led by Norwest Venture Partners. We&#x27;ll be using this money to hire more colleagues, so be sure to <a href=\"https://www.llamaindex.ai/careers\" rel=\"noreferrer noopener\">check out our open positions</a>!</p><p><strong>ü§© The Highlights:</strong></p><ul><li><strong>LlamaExtract Now in Public Beta:</strong> Simplify the extraction of structured data from unstructured documents with LlamaExtract. Perfect for finance, HR, and healthcare professionals. <a href=\"https://t.co/iiExmu0rbj\" rel=\"noreferrer noopener\">Read the full release blog</a> | <a href=\"https://t.co/zqUqveKp6b\" rel=\"noreferrer noopener\">Sign up today</a>.</li><li><strong>Agentic Productivity Applications:</strong> Check out this CRM assistant, an awesome example of what you can build with LlamaIndex! <a href=\"https://t.co/dAoZX3TnfI\" rel=\"noreferrer noopener\">Explore here</a>.</li></ul><p><strong>üó∫Ô∏è LlamaCloud &amp; LlamaParse:</strong></p><ul><li><strong>LlamaExtract Features:</strong> Define and customize schemas for data extraction, automatically extract well-typed data from diverse document formats, and integrate with Python SDK for scalable batch processing. <a href=\"https://t.co/iiExmu0rbj\" rel=\"noreferrer noopener\">Read the full release blog</a>.</li><li><strong>Parse With Agent Mode Updates:</strong> Our Parse With Agent mode now supports @AnthropicAI Claude Sonnet 3.7 and @google Gemini 2.0 Flash for improved table parsing and cross-page consistency. <a href=\"https://t.co/yQGTiRSNvj\" rel=\"noreferrer noopener\">Sign up for LlamaParse today</a> | <a href=\"https://t.co/15neOxPsyY\" rel=\"noreferrer noopener\">Read more in our docs</a>.</li></ul><p><strong>‚úçÔ∏è Community:</strong></p><ul><li><strong>Tutorial on Building a Workflow-Based Travel Planner:</strong> Step-by-step guide by RS Rohan on creating an advanced travel planner using @llama_index. <a href=\"https://t.co/4D48XuJQEM\" rel=\"noreferrer noopener\">Watch the tutorial video</a> | <a href=\"https://t.co/B38vAixzz5\" rel=\"noreferrer noopener\">Full repo on @github</a>.</li><li><strong>AI Agent that Generates Tetris:</strong> A tutorial from @KaranVaidya6 on building an AI agent that autonomously creates games. <a href=\"https://t.co/HxPXW8Nci7\" rel=\"noreferrer noopener\">Check it out</a>.</li><li><strong>Building the &quot;World&#x27;s Fastest&quot; RAG:</strong> Insights from @akshay_pachaar on using @llama_index for orchestration and @qdrant_engine for vector database optimization. <a href=\"https://t.co/cTdgWi1r77\" rel=\"noreferrer noopener\">Read more</a>.</li><li><strong>Exclusive Talks on AI Infrastructure:</strong> Join us for an eye-opening event on March 5 with @gokoyeb and @tenstorrent. <a href=\"https://t.co/te6M38fwSP\" rel=\"noreferrer noopener\">RSVP required</a>.</li></ul><p>Thank you for being part of our community! We‚Äôre excited to see what you build with LlamaIndex and LlamaParse. If you have any questions or feedback, feel free to reach out!</p>",
            "tags": [
                "LlamaIndex"
            ]
        },
        {
            "title": "Europe is finally getting serious about commercial rockets",
            "source": "MIT Tech Review AI",
            "url": "https://www.technologyreview.com/2025/03/20/1113582/europe-is-finally-getting-serious-about-commercial-rockets/",
            "published": "Thu, 20 Mar 2025 18:19:14 +0000",
            "summary": "Europe is on the cusp of a new dawn in commercial space technology. As global political tensions intensify and relationships with the US become increasingly strained, several European companies are now planning to conduct their own launches in an attempt to reduce the continent‚Äôs reliance on American rockets. In the coming days, Isar Aerospace, a&#8230;",
            "tags": [
                "MIT"
            ]
        },
        {
            "title": "Streamline AWS resource troubleshooting with Amazon Bedrock Agents and AWS Support Automation Workflows",
            "source": "AWS ML Blog",
            "url": "https://aws.amazon.com/blogs/machine-learning/streamline-aws-resource-troubleshooting-with-amazon-bedrock-agents-and-aws-support-automation-workflows/",
            "published": "Thu, 20 Mar 2025 17:27:17 +0000",
            "summary": "AWS provides a powerful tool called AWS Support Automation Workflows, which is a collection of curated AWS Systems Manager self-service automation runbooks. These runbooks are created by AWS Support Engineering with best practices learned from solving customer issues. They enable AWS customers to troubleshoot, diagnose, and remediate common issues with their AWS resources. In this post, we explore how to use the power of Amazon Bedrock Agents and AWS Support Automation Workflows to create an intelligent agent capable of troubleshooting issues with AWS resources.",
            "tags": [
                "AWS"
            ]
        },
        {
            "title": "Create generative AI agents that interact with your companies‚Äô systems in a few clicks using Amazon Bedrock in Amazon SageMaker Unified Studio",
            "source": "AWS ML Blog",
            "url": "https://aws.amazon.com/blogs/machine-learning/create-generative-ai-agents-that-interact-with-your-companies-systems-in-a-few-clicks-using-amazon-bedrock-in-amazon-sagemaker-unified-studio/",
            "published": "Thu, 20 Mar 2025 17:24:37 +0000",
            "summary": "In this post, we demonstrate how to use Amazon Bedrock in SageMaker Unified Studio to build a generative AI application to integrate with an existing endpoint and database.",
            "tags": [
                "AWS"
            ]
        },
        {
            "title": "Open R1: How to use OlympicCoder locally for coding?",
            "source": "Hugging Face",
            "url": "https://huggingface.co/blog/olympic-coder-lmstudio",
            "published": "Thu, 20 Mar 2025 00:00:00 GMT",
            "summary": "No summary available.",
            "tags": [
                "HuggingFace"
            ]
        },
        {
            "title": "Parsing PDFs with LlamaParse: a how-to guide",
            "source": "LlamaIndex",
            "url": "https://www.llamaindex.ai/blog/pdf-parsing-llamaparse",
            "published": "Thu, 20 Mar 2025 00:00:00 GMT",
            "summary": "<p>Generative AI (GenAI) is rapidly and radically changing how we produce and consume information. But it‚Äôs a ravenous beast when it comes to data.</p><p></p><p>In order to reach timely and relevant conclusions, it must consume large volumes of accurate data. The large language models that drive much of AI are often trained on public web pages due to their abundance and easy access. However, not all information is available in HTML.</p><p></p><p>Millions of Adobe PDF (Portable Document Format) documents contain data in the form of facts, figures, equations, laws and regulations, etc. that could be extremely useful to extract and store. Getting that data out of those PDFs can be a challenge.</p><p></p><p>LlamaIndex‚Äôs <a href=\"https://www.google.com/url?q=https://www.llamaindex.ai/llamaparse&amp;sa=D&amp;source=editors&amp;ust=1742501362713819&amp;usg=AOvVaw2EsHTr1sNhRJg7t24juyyI\" rel=\"noreferrer noopener\">LlamaParse</a>¬†simplifies extracting information from PDFs. Let us show you how it‚Äôs done with just a few lines of code.</p><h2>Challenges with parsing PDFs</h2><p>Unlike HTML, which inherently provides some structure to the content it presents, PDF was originally created to preserve the visual look of a printed document. Although the ability to encode structural metadata was eventually added, doing so can be a cumbersome process.</p><p></p><p>Sadly, apps that generate PDFs with included structural metadata often just get it wrong. PDFs generated by Adobe‚Äôs InDesign, for example, will often set the reading order of a page based upon the order the designer worked on the elements on that page.</p><h2>What is LlamaParse?</h2><p><a href=\"https://www.google.com/url?q=https://www.llamaindex.ai/llamaparse&amp;sa=D&amp;source=editors&amp;ust=1742501362714526&amp;usg=AOvVaw3rHjuOc-ZIrKZaqMTkQeHv\" rel=\"noreferrer noopener\">LlamaParse</a>¬†is a GenAI-native parsing platform for parsing and transforming complex documents into clean data for LLM applications. LlamaParse integrates with <a href=\"https://www.google.com/url?q=https://docs.llamaindex.ai/en/stable/&amp;sa=D&amp;source=editors&amp;ust=1742501362714675&amp;usg=AOvVaw1kDCplWad_Qh0KztgOi0nP\" rel=\"noreferrer noopener\">LlamaIndex</a>, the open source data orchestration framework for building <a href=\"https://www.google.com/url?q=https://www.cloudflare.com/learning/ai/what-is-large-language-model/&amp;sa=D&amp;source=editors&amp;ust=1742501362714803&amp;usg=AOvVaw1tP2RmS_VMjERKaDz-_zhr\" rel=\"noreferrer noopener\">large language model</a>¬†(LLM) applications. LlamaIndex makes it easier to build agents and the contextual data that supports them, leveraging AI to extract information from a number of document formats ‚Äî including PDFs.</p><p></p><p>LlamaParse is really good at:</p><p></p><p>‚úÖ Parsing a variety of unstructured file types (.pdf, .pptx, .docx, .xlsx, .html, jpeg, <a href=\"https://www.google.com/url?q=https://docs.cloud.llamaindex.ai/llamaparse/features/supported_document_types&amp;sa=D&amp;source=editors&amp;ust=1742501362715236&amp;usg=AOvVaw2hGgMXJ4xiLd6y0r9AxbSt\" rel=\"noreferrer noopener\">and more</a>).</p><p>‚úÖ Parsing embedded tables accurately into text and semi-structured representations.</p><p>‚úÖ Extracting data from visual elements (images/diagrams).</p><p>‚úÖ Using natural language instructions to customize the output how you want it.</p><h2>Benefits of using LlamaParse for PDF extraction</h2><p>You can parse PDFs on your own or with a standard, non-GenAI-enabled PDF parser. However, using LlamaParse provides numerous improvements:</p><p></p><ul><li>Significantly reduces the time and effort spent on data extraction by leveraging LLM intelligence to reduce the manual work involved in data extraction</li><li>Increases the volume of data available for your GenAI apps by freeing it from its sources</li><li>Converts unstructured data into structured data</li></ul><h2>Extracting and storing information from PDFs using LlamaParse</h2><p>You can use LlamaParse via our UI (<a href=\"https://www.google.com/url?q=https://docs.cloud.llamaindex.ai/&amp;sa=D&amp;source=editors&amp;ust=1742501362716368&amp;usg=AOvVaw1vf-my5SRwEiAl-9CuTXsJ\" rel=\"noreferrer noopener\">LlamaCloud</a>), the API, or one of our language SDKs. Below we‚Äôll demonstrate some of LlamaParse‚Äôs features using Python. If you would prefer to try LlamaParse without the bother of coding, you can <a href=\"https://www.google.com/url?q=https://cloud.llamaindex.ai/login&amp;sa=D&amp;source=editors&amp;ust=1742501362716538&amp;usg=AOvVaw1SNXNdBvt9d2uvHUOLRlGn\" rel=\"noreferrer noopener\">create a free LlamaCloud account</a>¬†and experiment using some of your own documents.</p><h3>Getting started: Installing LlamaIndex and LlamaParse</h3><p>First we need to install LlamaIndex and LlamaParse to make them available for our Python scripts.</p><p></p><p>Caution:¬†We recommend creating and activating a virtual Python environment before proceeding to avoid issues caused by conflicting dependency versions.</p><pre><code>pip install llama-index\npip install llama-parse</code></pre><h3>API key</h3><p>You also need an API key. To create one, <a href=\"https://www.google.com/url?q=https://cloud.llamaindex.ai/login&amp;sa=D&amp;source=editors&amp;ust=1742501362717690&amp;usg=AOvVaw1sts-GKn_FljzpdvxKzDF-\" rel=\"noreferrer noopener\">create a free LlamaCloud account</a>.</p><img src=\"https://cdn.sanity.io/images/7m9jw85w/production/9a07f3373c43df2983a3f4b1540ec51f59a32a8d-894x735.png?fit=max&amp;auto=format\" /><p>Once you have created an account and are logged in, click API Keys¬†from the left navigation and then the Generate New Key¬†button.<br /></p><img src=\"https://cdn.sanity.io/images/7m9jw85w/production/fcee80081c4f847ebe11642a21fa12c8094d9aea-1304x806.png?fit=max&amp;auto=format\" /><p>Caution: Once your key is displayed, copy it and save it to a secure location. You won‚Äôt be able to redisplay it once you dismiss the screen. If you lose your key, you should revoke it and create a new one.</p><p></p><p>We recommend setting your API as an environmental variable in your Python virtual environment.</p><pre><code>export LLAMA_CLOUD_API_KEY=&apos;yourkey12345‚Ä¶.&quot;</code></pre><p>Now we‚Äôre ready to begin parsing PDF files. Let‚Äôs write some code.</p><h3>Parse your first PDF with LlamaParse and Python</h3><p>We‚Äôll begin by parsing a two-page report comparing investment returns from the Nasdaq-100 vs. the S&amp;P 500. You can <a href=\"https://www.google.com/url?q=https://indexes.nasdaqomx.com/docs/NDX-vs-SPX_2%2520pager.pdf&amp;sa=D&amp;source=editors&amp;ust=1742501362719332&amp;usg=AOvVaw3yW1k9wX39d0X0bZTYEyQX\" rel=\"noreferrer noopener\">download the PDF file</a>¬†with your browser or by using wget.</p><pre><code>wget https://indexes.nasdaqomx.com/docs/NDX-vs-SPX_2%20pager.pdf</code></pre><p>Now we‚Äôll create a simple Python script to parse the PDF file and save its content as markdown.</p><pre><code>from llama_parse import LlamaParse\n\n\nparser = LlamaParse(\n   # api_key=&quot;llx-...&quot;,  # if you did not create an environmental variable you can set the API key here\n   result_type=&quot;markdown&quot;,  # &quot;markdown&quot; and &quot;text&quot; are available\n   )\n\nfile_name = &quot;./NDX-vs-SPX_2 pager.pdf&quot;\nextra_info = {&quot;file_name&quot;: file_name}\n\nwith open(f&quot;./{file_name}&quot;, &quot;rb&quot;) as f:\n   # must provide extra_info with file_name key with passing file object\n   documents = parser.load_data(f, extra_info=extra_info)\n\n# with open(&apos;output.md&apos;, &apos;w&apos;) as f:\n   # print(documents, file=f)\n\n# Write the output to a file\nwith open(&quot;output.md&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:\n   for doc in documents:\n       f.write(doc.text)</code></pre><p>Save the script as parse.py¬†and then run it.</p><pre><code>python parse.py</code></pre><p>Once the script finishes, open output.md.¬†You‚Äôll see that LlamaParse has successfully extracted the content from the PDF and correctly applied structure via headers. Notice that the table at the bottom of the first page was also recreated in markdown.</p><pre><code>| |Nasdaq-100 TR|S&amp;P 500 TR|\n|---|---|---|\n|Cumulative Return|315%|156%|\n|Annualized Return|13%|9%|\n|Annualized Volatility|22%|20%|</code></pre><h3>Extracting data from charts and graphs</h3><p>However, you may notice that the data from the two graphs on the first page are missing. This is actually by design. LlamaParse supports multiple parsing modes, which allows you to balance speed, cost, and advanced parsing power based upon your needs at the moment.</p><p></p><p>The default mode, which we used above, skips most graphs since they require more advanced and costly processing. But we can enable LlamaParse to utilize a different mode with a slight configuration change to our parser.</p><pre><code>from llama_parse import LlamaParse\n\n\nparser = LlamaParse(\n   # api_key=&quot;llx-...&quot;,  # if you did not create an environmental variable you can set the API key here\n   result_type=&quot;markdown&quot;,  # &quot;markdown&quot; and &quot;text&quot; are available,\n\n    extract_charts=True,\n\n    auto_mode=True,\n\n    auto_mode_trigger_on_image_in_page=True,\n\n    auto_mode_trigger_on_table_in_page=True,\n   )\n\nfile_name = &quot;./NDX-vs-SPX_2 pager.pdf&quot;\nextra_info = {&quot;file_name&quot;: file_name}\n\nwith open(f&quot;./{file_name}&quot;, &quot;rb&quot;) as f:\n   # must provide extra_info with file_name key with passing file object\n   documents = parser.load_data(f, extra_info=extra_info)\n\n# with open(&apos;output.md&apos;, &apos;w&apos;) as f:\n   # print(documents, file=f)\n\n# Write the output to a file\nwith open(&quot;output.md&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:\n   for doc in documents:\n       f.write(doc.text)</code></pre><p>When the parser completes its work, you‚Äôll see, for example, that the industry breakdown chart on the second page has been parsed and rendered as a table.</p><pre><code>Industry (ICB) Breakdown\n\n| Industry | Nasdaq-100 Industry (ICB) Weights | S&amp;P 500 Industry (ICB) Weights |\n|----------|-----------------------------------|--------------------------------|\n| Technology | 55% | 22% |\n| Consumer Services | 25% | 14% |\n| Health Care | 8% | 13% |\n| Consumer Goods | 6% | 8% |\n| Industrials | 6% | 12% |\n| Telecommunications | 1% | 2% |\n| Utilities | 3% | 3% |\n| Financials | - | 18% |\n| Oil &amp; Gas | - | 5% |\n| Basic Materials | 2% | 2% |</code></pre><p>Learn more about <a href=\"https://www.google.com/url?q=https://docs.cloud.llamaindex.ai/llamaparse/parsing/parsing_modes&amp;sa=D&amp;source=editors&amp;ust=1742501362726480&amp;usg=AOvVaw2pf1GMQTZWhNvP5yci_OH9\" rel=\"noreferrer noopener\">parsing modes</a>¬†and how LlamaParse auto mode enables you to <a href=\"https://www.google.com/url?q=https://www.llamaindex.ai/blog/optimize-parsing-costs-with-llamaparse-auto-mode&amp;sa=D&amp;source=editors&amp;ust=1742501362726680&amp;usg=AOvVaw2GumQK5RNfQxQu4HkVOP17\" rel=\"noreferrer noopener\">optimize your parsing costs</a>¬†by only invoking the premium modes when they are genuinely needed.</p><h3>Storing your data in a vector database</h3><p>Once you‚Äôve extracted your data from the PDF, you can send it to a vector database such as Elasticsearch. You‚Äôll need API keys from <a href=\"https://www.google.com/url?q=https://openai.com/api/&amp;sa=D&amp;source=editors&amp;ust=1742501362726974&amp;usg=AOvVaw1zyAl9ogd9PPx7uPBr0fug\" rel=\"noreferrer noopener\">OpenAI</a>¬†and <a href=\"https://www.google.com/url?q=https://www.elastic.co/cloud&amp;sa=D&amp;source=editors&amp;ust=1742501362727068&amp;usg=AOvVaw0IJW7jnIttYGzFj0ekA2ml\" rel=\"noreferrer noopener\">Elastic Cloud</a>, as well as a few more dependencies installed including nest_asyncio. From there it‚Äôs just a few additional lines of code to store your data.</p><pre><code>from llama_index.vector_stores.elasticsearch import ElasticsearchStore\n\nes_store = ElasticsearchStore(\n    index_name=&quot;llama-parse-docs&quot;,\n    es_cloud_id=es_cloud_id,  # found within the deployment page\n    es_api_key=es_api_key,  # create an API key within Kibana (Security -&gt; API Keys)\n)\n\nfrom llama_index.core.node_parser import SimpleNodeParser\nnode_parser = SimpleNodeParser()\n\nnodes = node_parser.get_nodes_from_documents(documents)\n\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.core import VectorStoreIndex, StorageContext\n\nstorage_context = StorageContext.from_defaults(vector_store=es_store)\nindex = VectorStoreIndex(\n    nodes=nodes,\n    storage_context=storage_context,\n    embed_model=OpenAIEmbedding(api_key=openai_api_key),\n)</code></pre><p>We won‚Äôt go through the full process here, but we‚Äôve prepared detailed examples of <a href=\"https://www.google.com/url?q=https://github.com/run-llama/llama_cloud_services/blob/main/examples/parse/demo_elasticsearch_vectordb.ipynb&amp;sa=D&amp;source=editors&amp;ust=1742501362730585&amp;usg=AOvVaw1BmpKNaBVe-t4AQzcHS99o\" rel=\"noreferrer noopener\">sending extracted data to Elasticsearch</a>¬†as well as <a href=\"https://www.google.com/url?q=https://github.com/run-llama/llama_cloud_services/blob/main/examples/parse/demo_advanced_astradb.ipynb&amp;sa=D&amp;source=editors&amp;ust=1742501362730789&amp;usg=AOvVaw30iqaa25dX6AGhPqyzcliY\" rel=\"noreferrer noopener\">to Astra DB</a>¬†in our repo.</p><h2>Fine-tuning your PDF</h2><p>Almost any document that can be displayed on a computer screen can be saved as a PDF, which, as we discussed earlier, makes it difficult to parse them consistently. LlamaParse supports numerous ways to adjust the parsing instructions fed to the LLM for better results or advanced capabilities.</p><h3>Translate your output</h3><p>Have a document in Spanish but need to store its content in English? LlamaParse can do that.</p><p>Download <a href=\"https://www.google.com/url?q=https://www.scusd.edu/sites/main/files/file-attachments/howtohelpyourchildsucceedinschoolspanish.pdf&amp;sa=D&amp;source=editors&amp;ust=1742501362731410&amp;usg=AOvVaw3sX6q3YFDRR4091l5csc9M\" rel=\"noreferrer noopener\">this Spanish language document</a>.</p><pre><code>wget https://www.scusd.edu/sites/main/files/file-attachments/howtohelpyourchildsucceedinschoolspanish.pdf</code></pre><p>LlamaParse lets you customize the prompt sent to the LLM that initiates parsing.</p><pre><code>from llama_parse import LlamaParse\n\nparser = LlamaParse(\n   result_type=&quot;markdown&quot;,\n\n    user_prompt=&quot;If the input is not in English, translate the output into English.&quot;\n   )\n\nfile_name = &quot;./howtohelpyourchildsucceedinschoolspanish.pdf&quot;\nextra_info = {&quot;file_name&quot;: file_name}\n\nwith open(f&quot;./{file_name}&quot;, &quot;rb&quot;) as f:\n   # must provide extra_info with file_name key with passing file object\n   documents = parser.load_data(f, extra_info=extra_info)\n\n# with open(&apos;output.md&apos;, &apos;w&apos;) as f:\n   # print(documents, file=f)\n\n# Write the output to a file\nwith open(&quot;output.md&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:\n   for doc in documents:\n       f.write(doc.text)</code></pre><p>Prompts are incredibly powerful and provide you with granular control of your output. Learn more about <a href=\"https://www.google.com/url?q=https://docs.cloud.llamaindex.ai/llamaparse/features/prompts&amp;sa=D&amp;source=editors&amp;ust=1742501362734354&amp;usg=AOvVaw2W2sA_i9o3cWNbUFFHq_F5\" rel=\"noreferrer noopener\">how to use prompts</a>¬†in the docs.</p><h3>Limiting/targeting your parsing</h3><p>If you only need to parse selected pages from your PDF you don‚Äôt need to extract those pages from your source file before parsing. Just pass the pages you wish to parse.</p><pre><code>parser = LlamaParse(\n   target_pages=&quot;0,10,12,22-33&quot;\n)</code></pre><p>Note that pages are numbered starting at 0.</p><p>If your source file has headers or footers, you can instruct LlamaParse to ignore content that falls within a specified section of the page. Here we instruct the parser to ignore the top 10% of the page and the bottom 5%.</p><pre><code>parser = LlamaParse(\n   bbox_top=0.1,\n   bbox_bottom=0.05\n)</code></pre><h3>More examples</h3><p>There are dozens of additional ways you can fine tune your parsing to fit your specific needs. You can apply output schemas to create <a href=\"https://www.google.com/url?q=https://docs.cloud.llamaindex.ai/llamaparse/schemas/invoice&amp;sa=D&amp;source=editors&amp;ust=1742501362736095&amp;usg=AOvVaw1EypyIqFMncJUTepGjExq8\" rel=\"noreferrer noopener\">invoices</a>¬†and <a href=\"https://www.google.com/url?q=https://docs.cloud.llamaindex.ai/llamaparse/schemas/resume&amp;sa=D&amp;source=editors&amp;ust=1742501362736306&amp;usg=AOvVaw11HumjtFAZSF5mbkuF84uN\" rel=\"noreferrer noopener\">resumes</a>. Although we have focused on parsing PDF files, LlamaParse supports extracting data from <a href=\"https://www.google.com/url?q=https://docs.cloud.llamaindex.ai/llamaparse/features/supported_document_types&amp;sa=D&amp;source=editors&amp;ust=1742501362736480&amp;usg=AOvVaw2Uu3mQBf1_YFlG3c1Lmf3v\" rel=\"noreferrer noopener\">dozens of different file formats</a>, including audio files.</p><p>To help you explore the full range of capabilities, we‚Äôve compiled dozens of examples and made them <a href=\"https://www.google.com/url?q=https://github.com/run-llama/llama_cloud_services/tree/main/examples&amp;sa=D&amp;source=editors&amp;ust=1742501362736782&amp;usg=AOvVaw3x9mKu8Az0Hoai43hEuFLe\" rel=\"noreferrer noopener\">available in our repo</a>.<br /></p><h2>Conclusion</h2><p>LlamaParse makes parsing PDFs and other unstructured data easier and less labor-intensive than ever. It exponentially increases the data available for your GenAI apps while simultaneously freeing your developers to innovate rather than wasting time writing bespoke apps to extract and parse data from hard-to-crack data sources.</p><p></p><p><a href=\"https://www.google.com/url?q=https://cloud.llamaindex.ai&amp;sa=D&amp;source=editors&amp;ust=1742501362737130&amp;usg=AOvVaw3xeDrhWEINjOYp1rSAv809\" rel=\"noreferrer noopener\">Get started with LlamaParse today</a>¬†and parse up to 1000 pages per day for free.</p>",
            "tags": [
                "LlamaIndex"
            ]
        },
        {
            "title": "Unlocking the future of manufacturing with AI-powered digital thread",
            "source": "Microsoft AI",
            "url": "https://www.microsoft.com/en-us/industry/blog/manufacturing-and-mobility/2025/03/13/unlocking-the-future-of-manufacturing-with-ai-powered-digital-thread/",
            "published": "Thu, 13 Mar 2025 15:00:00 +0000",
            "summary": "<p>The era of AI and digital threads has arrived, and it‚Äôs delivering real value for the world‚Äôs leading manufacturers today.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/industry/blog/manufacturing-and-mobility/2025/03/13/unlocking-the-future-of-manufacturing-with-ai-powered-digital-thread/\">Unlocking the future of manufacturing with AI-powered digital thread</a> appeared first on <a href=\"https://www.microsoft.com/en-us/ai/blog\">Microsoft AI Blogs</a>.</p>",
            "tags": [
                "Microsoft"
            ]
        },
        {
            "title": "4 real business benefits of Microsoft AI",
            "source": "Microsoft AI",
            "url": "https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/03/13/4-real-business-benefits-of-microsoft-ai/",
            "published": "Thu, 13 Mar 2025 15:00:00 +0000",
            "summary": "<p>At Microsoft, we‚Äôre working with thousands of  customers across industries and around the world to help them realize the value of AI.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/03/13/4-real-business-benefits-of-microsoft-ai/\">4 real business benefits of Microsoft AI</a> appeared first on <a href=\"https://www.microsoft.com/en-us/ai/blog\">Microsoft AI Blogs</a>.</p>",
            "tags": [
                "Microsoft"
            ]
        },
        {
            "title": "The Cybernetic Teammate: A Field Experiment on Generative AI Reshaping Teamwork",
            "source": "Hacker News AI",
            "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5188231",
            "published": "Sat, 22 Mar 2025 12:53:44 +0000",
            "summary": "<p>Article URL: <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5188231\">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5188231</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43445389\">https://news.ycombinator.com/item?id=43445389</a></p>\n<p>Points: 1</p>\n<p># Comments: 0</p>",
            "tags": [
                "HackerNews"
            ]
        },
        {
            "title": "Show HN : Rollout - Create websites with AI",
            "source": "Hacker News AI",
            "url": "https://rollout.site/",
            "published": "Sat, 22 Mar 2025 12:53:14 +0000",
            "summary": "<p>Article URL: <a href=\"https://rollout.site/\">https://rollout.site/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43445386\">https://news.ycombinator.com/item?id=43445386</a></p>\n<p>Points: 1</p>\n<p># Comments: 0</p>",
            "tags": [
                "HackerNews"
            ]
        },
        {
            "title": "AI will transform how we monetize software",
            "source": "Hacker News AI",
            "url": "https://getlago.substack.com/p/why-seat-based-pricing-will-slowly",
            "published": "Sat, 22 Mar 2025 12:33:17 +0000",
            "summary": "<p>Article URL: <a href=\"https://getlago.substack.com/p/why-seat-based-pricing-will-slowly\">https://getlago.substack.com/p/why-seat-based-pricing-will-slowly</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43445293\">https://news.ycombinator.com/item?id=43445293</a></p>\n<p>Points: 2</p>\n<p># Comments: 0</p>",
            "tags": [
                "HackerNews"
            ]
        },
        {
            "title": "Show HN: Cue AI ‚Äì Create Personalized Mini-Apps Instantly (iOS and Android)",
            "source": "Hacker News AI",
            "url": "https://apps.apple.com/au/app/cue-ai/id6740705859",
            "published": "Sat, 22 Mar 2025 12:23:27 +0000",
            "summary": "<p>Hi HN!<p>I've built Cue AI, a personal assistant app that instantly creates personalized routines (\"mini-apps\") simply from text, voice input, or even photos. My goal was to eliminate the hassle of downloading multiple apps or dealing with long, tedious setup processes.<p>Examples of what you can quickly create with Cue AI:<p>-  Snap a photo of your plant, get a personalized watering routine.\n-  Instantly generate step-by-step cooking guides with full ingredient lists.\n-  Easily organize household chores‚Äîreminders for laundry, cleaning, and more.\n-  Quickly make custom quizzes, trivia games, or educational flashcards.\n-  Specialized sessions for professionals, such as speech therapy exercises.<p>Cue AI is live and available for free (with premium options) on both iOS and Android. I'd genuinely appreciate your feedback, ideas, and suggestions‚Äîespecially if you're into productivity, personal development, or simplifying daily life!<p>Try it out here:  \n- [Cue AI for iOS](<a href=\"https://apps.apple.com/au/app/cue-ai/id6740705859\">https://apps.apple.com/au/app/cue-ai/id6740705859</a>)  \n- [Cue AI for Android](<a href=\"https://play.google.com/store/apps/details?id=cueai.app&amp;pli=1\">https://play.google.com/store/apps/details?id=cueai.app&amp;pli=...</a>)<p>Would love your thoughts on how it could be improved. Thanks!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43445254\">https://news.ycombinator.com/item?id=43445254</a></p>\n<p>Points: 1</p>\n<p># Comments: 0</p>",
            "tags": [
                "HackerNews"
            ]
        },
        {
            "title": "Now the Kanban for AI Agents UI Is Open Source Too ‚Üí MIT Licensed",
            "source": "Hacker News AI",
            "url": "https://github.com/kaiban-ai/kaiban-board",
            "published": "Sat, 22 Mar 2025 11:44:37 +0000",
            "summary": "<p>Article URL: <a href=\"https://github.com/kaiban-ai/kaiban-board\">https://github.com/kaiban-ai/kaiban-board</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43445101\">https://news.ycombinator.com/item?id=43445101</a></p>\n<p>Points: 2</p>\n<p># Comments: 0</p>",
            "tags": [
                "HackerNews"
            ]
        },
        {
            "title": "Evolving Product Operating Models in the Age of AI",
            "source": "Towards Data Science",
            "url": "https://towardsdatascience.com/evolving-product-operating-models-in-the-age-of-ai/",
            "published": "Sat, 22 Mar 2025 01:18:34 +0000",
            "summary": "<p>This article explores how the product operating model, and the core competencies of empowered product teams in particular, can evolve to face the emerging opportunities and challenges in the age of AI.</p>\n<p>The post <a href=\"https://towardsdatascience.com/evolving-product-operating-models-in-the-age-of-ai/\">Evolving Product Operating Models in the Age of AI</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
            "tags": [
                "TDS"
            ]
        },
        {
            "title": "How do I speed up my agent?",
            "source": "LangChain",
            "url": "https://blog.langchain.dev/how-do-i-speed-up-my-agent/",
            "published": "Sat, 15 Mar 2025 18:34:47 GMT",
            "summary": "<p>I get this question a bunch. Developers generally first spend time getting the agent to work, but then they turn their attention to speed and cost. There are few things we see developers doing:</p><ul><li>Identifying where the latency is coming from</li><li>Changing the UX to reduce the &#x201c;perceived&#x201d;</li></ul>",
            "tags": [
                "LangChain"
            ]
        },
        {
            "title": "MCP: Flash in the Pan or Future Standard?",
            "source": "LangChain",
            "url": "https://blog.langchain.dev/mcp-fad-or-fixture/",
            "published": "Sat, 08 Mar 2025 16:25:03 GMT",
            "summary": "<p><em>Model Context Protocol (MCP) is creating quite the stir on Twitter &#x2013; but is it actually useful, or just noise? In this back and forth, Harrison Chase (LangChain CEO) and Nuno Campos (LangGraph Lead) debate whether MCP lives up to the hype.</em></p><p><strong><em><u>Harrison:</u></em></strong> I&#x2019;ll take the position that</p>",
            "tags": [
                "LangChain"
            ]
        },
        {
            "title": "Mining Financial Data from SEC Filings with LlamaExtract",
            "source": "LlamaIndex",
            "url": "https://www.llamaindex.ai/blog/mining-financial-data-from-sec-filings-with-llamaextract",
            "published": "Mon, 17 Mar 2025 00:00:00 GMT",
            "summary": "<p>Extracting structured information from lengthy documents is a common need we hear from customers. Whether you are analyzing SEC filings, legal contracts, research papers, or technical documentation, LlamaExtract can help you transform complex, long-form documents into structured, actionable data that can be used downstream as part of an automated process.</p><h2>Why Extract Structured data from 10-Ks</h2><p>In working with our financial services customers, we have come across several use cases where structured data extraction from 10Ks would be valuable. Some examples are</p><ul><li><strong>Financial Analysis and Benchmarking:</strong> Structured data extraction enables analysts and investors to systematically evaluate a company&#x27;s financial health by organizing key metrics such as revenue, operating income, and net income</li><li><strong>Risk Assessment and Management:</strong> By extracting and structuring information on risk factors disclosed in 10-K reports, organizations can identify and monitor potential risks more effectively</li><li><strong>Investment Decision-Making:</strong> Investors rely on structured data from 10-K reports to assess the viability and potential returns of investment opportunities. Organizing financial statements, management discussions, and market analyses into structured formats enables more accurate evaluations and comparisons, aiding in sound investment decisions.</li></ul><h2>Challenges of Extraction from 10-K/Q Filings</h2><p>While extracting structured data from SEC 10-K/Q filings is high value, it exemplifies the challenges of long-form document extraction.</p><ul><li>These reports often exceed 100 pages and contain densely packed information across multiple sections with varying structures. Traditional extraction methods typically fail because they can&#x27;t maintain context across distant sections of a document or struggle with extraction from tabular data.</li><li>These documents have a loosely defined structure and the reported metrics and sections may differ based on the company&#x27;s operations. We ideally want to capture fields that are common across different companies while still allowing for individual variation in reporting metrics and fields.</li></ul><p>For reference, here is Nvidia‚Äôs 2024 10-K filing with the <a href=\"https://www.sec.gov/ix?doc=/Archives/edgar/data/0001045810/000104581025000023/nvda-20250126.htm\" rel=\"noreferrer noopener\">SEC</a>. We will be using this as an example in this post. To follow along, you can clone the <a href=\"https://github.com/run-llama/llama_cloud_services/blob/main/examples/extract/sec_10k_filing.ipynb\" rel=\"noreferrer noopener\">notebook</a> from our examples folder. Let&#x27;s see how LlamaExtract addresses the challenges of converting these documents into a structured well-typed format.</p><h2>Building an Effective Extraction Schema</h2><p>The foundation of successful extraction is a well-designed schema. A well-designed schema is one that captures your information of interest and generalizes to your target documents, i.e. documents have the relevant information to populate the fields in the schema, and likewise, the schema contains enough information to specify ‚Äúhow‚Äù to extract this data from the target documents.</p><p>For SEC filings, we create a comprehensive schema that captures filing information, company profile, financial highlights, business segments, geographic data, risk factors, and management discussions.</p><p><strong>1. Using Python SDK with Pydantic for Schema Specification</strong> </p><p>We can use our Python SDK to build the schema, which looks like the following. Refer to the notebook for additional classes for extracting financial highlights, information from different financial statements, management discussions, etc.</p><pre><code>from typing import Literal, Optional, List\nfrom pydantic import BaseModel, Field\n\nclass FilingInfo(BaseModel):\n    &quot;&quot;&quot;Basic information about the SEC filing&quot;&quot;&quot;\n    filing_type: Literal[&quot;10-K&quot;, &quot;10-Q&quot;, &quot;10-K/A&quot;, &quot;10-Q/A&quot;] = Field(\n        description=&quot;Type of SEC filing&quot;\n    )\n    filing_date: str = Field(description=&quot;Date when filing was submitted to SEC&quot;)\n    reporting_period_end: str = Field(description=&quot;End date of reporting period&quot;)\n    fiscal_year: int = Field(description=&quot;Fiscal year&quot;)\n    fiscal_quarter: int = Field(description=&quot;Fiscal quarter (if 10-Q)&quot;, ge=1, le=4)\n\n# Additional model classes for company profile, financial data, etc.\n</code></pre><p><strong>2. Using the Web UI</strong> </p><p>The notebook may give the impression that schema design is a one-shot process which is far from being the case. Usually, you start small, test the schema on a sample document, add descriptions and examples in case of inaccurate extractions and slowly and iteratively build your schema. This part might be easier to do with our <a href=\"https://cloud.llamaindex.ai/\" rel=\"noreferrer noopener\">Web UI</a>. We have provided a pre-defined 10-K/Q extraction schema that you can play around with and modify.</p><img src=\"https://cdn.sanity.io/images/7m9jw85w/production/40e27a968386dfdf9a481c00e915b43ff1b67cb0-1230x1758.png?fit=max&amp;auto=format\" /><p></p><h3>Tips for Long-Form Document Extraction Schema Design</h3><p>When working with extensive documents like SEC filings, consider these specialized schema design principles:</p><p><strong>1. Strategic Field Optionality</strong> </p><p>For long documents with varying content across different companies or document instances, be strategic about which fields are required versus optional:</p><pre><code># Making fields optional when they might not be present in all filings\nebitda: Optional[float] = Field(\n    None,\n    description=&quot;EBITDA (Earnings Before Interest, Taxes, Depreciation, Amortization)&quot;\n)</code></pre><p><em>Too many required fields may force hallucination, while too many optional fields might result in missed information. Find the right balance based on your document set.</em></p><p><strong>2. Clear Field Descriptions</strong> </p><p>In lengthy documents where similar concepts may appear in different contexts, precise field descriptions are essential. The more specific your descriptions, the more accurate your extraction results will be. As you find inaccuracies in the extractions, this is a good place to specify expected behavior by giving examples of what to do and what not to do.</p><pre><code>gross_margin: float = Field(description=&quot;Gross margin percentage&quot;)\nrevenue_percentage: Optional[float] = Field(\n    None, description=&quot;Percentage of total company revenue (not growth rate)&quot;\n)</code></pre><p><strong>3. Hierarchical Organization</strong> </p><p>Structure your schema to mirror the natural organization of the document. This hierarchical approach helps the extraction model maintain context across the document&#x27;s logical sections.<br /></p><pre><code>class SECFiling(BaseModel):\n    filing_info: FilingInfo = Field(description=&quot;Basic information about the filing&quot;)\n    company_profile: CompanyProfile = Field(description=&quot;Essential company information&quot;)\n    financial_highlights: FinancialHighlights = Field(\n        description=&quot;Key financial metrics from this reporting period&quot;\n    )\n    # Additional sections...\n</code></pre><p><strong>4. Include Page Tracking</strong> </p><p>For long documents, tracking where information was found is important for verification. We have included <code>page_numbers</code> in the schema to be able to verify which section of the document was used to source certain data. <em>Page numbers might be off by one due to the relative placement of the page numbers and the surrounding context from which the information is extracted, but it is a quick way to navigate to the relevant sections of the document and sanity test some fields. Providing an easier and more accurate way to cite source documents is high on our roadmap.</em></p><pre><code>page_numbers: List[int] = Field(\n    description=&quot;Page numbers where the financial metrics were extracted from&quot;\n)</code></pre><h2>Assessing Extraction Results</h2><p>Here&#x27;s the relevant section on financial highlights that was extracted. Take a look at the <a href=\"https://github.com/run-llama/llama_cloud_services/blob/main/examples/extract/sec_10k_filing.ipynb\" rel=\"noreferrer noopener\">notebook</a> to see the detailed extraction results.</p><pre><code>{\n &apos;financial_highlights&apos;: {\n  &apos;period_end&apos;: &apos;2025-01-26&apos;,\n  &apos;comparison_period_end&apos;: &apos;2024-01-28&apos;,\n  &apos;currency&apos;: &apos;USD&apos;,\n  &apos;unit&apos;: &apos;thousands&apos;,\n  &apos;revenue&apos;: 130497.0,\n  &apos;revenue_prior_period&apos;: 60922.0,\n  &apos;revenue_growth&apos;: 114.23,\n  &apos;gross_profit&apos;: 97858.0,\n  &apos;gross_margin&apos;: 75.0,\n  &apos;operating_income&apos;: 81453.0,\n  &apos;operating_margin&apos;: None,\n  &apos;net_income&apos;: 72880.0,\n  &apos;net_margin&apos;: 55.8,\n  &apos;eps&apos;: None,\n  &apos;diluted_eps&apos;: None,\n  &apos;ebitda&apos;: None,\n  &apos;free_cash_flow&apos;: None,\n  &apos;page_numbers&apos;: [40, 41, 55, 56, 68]\n },\n}</code></pre><p><br /></p><p>The gross margin of 75% was extracted from page 40 below and the revenue figures and are from page 41 in the document. You can verify that the geographic breakdown of revenue is extracted from page 79 correctly.</p><img src=\"https://cdn.sanity.io/images/7m9jw85w/production/00c78ad03d4063217dd8d73827704dfbbb1353fc-2058x712.png?fit=max&amp;auto=format\" /><p></p><h3>LlamaExtract is Available in Public Beta!</h3><p>LlamaExtract is now available for you to try out. It provides a comprehensive solution for structured data extraction workflows:</p><ul><li><strong>Schema Iteration using the Web UI</strong>: We have a <a href=\"https://cloud.llamaindex.ai/\" rel=\"noreferrer noopener\">Web UI</a> with a schema builder that can help you define your schema and iterate on different documents. We have a 10-K/Q schema for you to get started with if you are interested in trying this out. Start small and build from there! Refer to the tips above. Try your schema on different documents to see whether it generalizes to the target documents.</li><li><strong>Citations</strong>: For long-form document extraction, you can ask the extraction agent to provide page numbers for key figures extracted. This will help you quickly navigate to the relevant section of the document and verify the veracity of the information extracted. We are working on a more robust and convenient citation feature!</li><li><strong>Run scalable batch jobs</strong>: Once you have confidence that the extraction agent is working well, you can use your agent via our¬†<a href=\"https://github.com/run-llama/llama_cloud_services\" rel=\"noreferrer noopener\">Python SDK</a>¬†to run scalable batch jobs.</li></ul><p>Get started today! <a href=\"https://cloud.llamaindex.ai/\" rel=\"noreferrer noopener\">Sign up for LlamaCloud with LlamaExtract</a>.</p>",
            "tags": [
                "LlamaIndex"
            ]
        },
        {
            "title": "How C.H. Robinson is transforming the logistics industry with LangChain",
            "source": "LangChain",
            "url": "https://blog.langchain.dev/customers-chrobinson/",
            "published": "Mon, 10 Mar 2025 21:55:16 GMT",
            "summary": "Global logistics provider saves 600+ hours a day with tech they built using LangGraph, LangGraph Studio, and LangSmith developer tools.",
            "tags": [
                "LangChain"
            ]
        },
        {
            "title": "No More Tableau Downtime: Metadata API for Proactive Data¬†Health",
            "source": "Towards Data Science",
            "url": "https://towardsdatascience.com/no-more-tableau-downtime-metadata-api-for-proactive-data-health/",
            "published": "Fri, 21 Mar 2025 20:01:41 +0000",
            "summary": "<p>Leverage the power of the Metadata API to act on any potential data disruptions</p>\n<p>The post <a href=\"https://towardsdatascience.com/no-more-tableau-downtime-metadata-api-for-proactive-data-health/\">No More Tableau Downtime: Metadata API for Proactive Data¬†Health</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
            "tags": [
                "TDS"
            ]
        },
        {
            "title": "What Germany Currently Is Up To, Debt-Wise",
            "source": "Towards Data Science",
            "url": "https://towardsdatascience.com/what-germany-currently-is-up-to-debt-wise/",
            "published": "Fri, 21 Mar 2025 19:30:58 +0000",
            "summary": "<p>Billions, visualized to scale using python and HTML</p>\n<p>The post <a href=\"https://towardsdatascience.com/what-germany-currently-is-up-to-debt-wise/\">What Germany Currently Is Up To, Debt-Wise</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
            "tags": [
                "TDS"
            ]
        },
        {
            "title": "Google‚Äôs Data Science Agent: Can It Really Do Your Job?",
            "source": "Towards Data Science",
            "url": "https://towardsdatascience.com/googles-data-science-agent-can-it-really-do-your-job/",
            "published": "Fri, 21 Mar 2025 18:31:14 +0000",
            "summary": "<p>I tested Google‚Äôs Data Science Agent in Colab‚Äîhere‚Äôs what it got right (and where it failed)</p>\n<p>The post <a href=\"https://towardsdatascience.com/googles-data-science-agent-can-it-really-do-your-job/\">Google‚Äôs Data Science Agent: Can It Really Do Your Job?</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
            "tags": [
                "TDS"
            ]
        },
        {
            "title": "OpenAI has released its first research into how using ChatGPT affects people‚Äôs emotional wellbeing",
            "source": "MIT Tech Review AI",
            "url": "https://www.technologyreview.com/2025/03/21/1113635/openai-has-released-its-first-research-into-how-using-chatgpt-affects-peoples-emotional-wellbeing/",
            "published": "Fri, 21 Mar 2025 17:44:25 +0000",
            "summary": "OpenAI says over 400 million people use ChatGPT every week. But how does interacting with it affect us? Does it make us more or less lonely? These are some of the questions OpenAI set out to investigate, in partnership with the MIT Media Lab, in a pair of new studies.¬† They found that only a&#8230;",
            "tags": [
                "MIT"
            ]
        },
        {
            "title": "Build a generative AI enabled virtual IT troubleshooting assistant using Amazon Q Business",
            "source": "AWS ML Blog",
            "url": "https://aws.amazon.com/blogs/machine-learning/build-a-generative-ai-enabled-virtual-it-troubleshooting-assistant-using-amazon-q-business/",
            "published": "Fri, 21 Mar 2025 16:52:07 +0000",
            "summary": "Discover how to build a GenAI powered virtual IT troubleshooting assistant using Amazon Q Business. This innovative solution integrates with popular ITSM tools like ServiceNow, Atlassian Jira, and Confluence to streamline information retrieval and enhance collaboration across your organization. By harnessing the power of generative AI, this assistant can significantly boost operational efficiency and provide 24/7 support tailored to individual needs. Learn how to set up, configure, and leverage this solution to transform your enterprise information management.",
            "tags": [
                "AWS"
            ]
        },
        {
            "title": "Process formulas and charts with Anthropic‚Äôs Claude on Amazon Bedrock",
            "source": "AWS ML Blog",
            "url": "https://aws.amazon.com/blogs/machine-learning/process-formulas-and-charts-with-anthropics-claude-on-amazon-bedrock/",
            "published": "Fri, 21 Mar 2025 16:45:47 +0000",
            "summary": "In this post, we explore how you can use these multi-modal generative AI models to streamline the management of technical documents. By extracting and structuring the key information from the source materials, the models can create a searchable knowledge base that allows you to quickly locate the data, formulas, and visualizations you need to support your work.",
            "tags": [
                "AWS"
            ]
        },
        {
            "title": "Automate IT operations with Amazon Bedrock Agents",
            "source": "AWS ML Blog",
            "url": "https://aws.amazon.com/blogs/machine-learning/automate-it-operations-with-amazon-bedrock-agents/",
            "published": "Fri, 21 Mar 2025 16:37:27 +0000",
            "summary": "This post presents a comprehensive AIOps solution that combines various AWS services such as Amazon Bedrock, AWS Lambda, and Amazon CloudWatch to create an AI assistant for effective incident management. This solution also uses Amazon Bedrock Knowledge Bases and Amazon Bedrock Agents. The solution uses the power of Amazon Bedrock to enable the deployment of intelligent agents capable of monitoring IT systems, analyzing logs and metrics, and invoking automated remediation processes.",
            "tags": [
                "AWS"
            ]
        },
        {
            "title": "The Download: saving the ‚Äúdoomsday glacier,‚Äù and Europe‚Äôs hopes for its rockets",
            "source": "MIT Tech Review AI",
            "url": "https://www.technologyreview.com/2025/03/21/1113624/the-download-saving-the-doomsday-glacier-and-europes-hopes-for-its-rockets/",
            "published": "Fri, 21 Mar 2025 12:10:00 +0000",
            "summary": "This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. Inside a new quest to save the ‚Äúdoomsday glacier‚Äù The Thwaites glacier is a fortress larger than Florida, a wall of ice that reaches nearly 4,000 feet above the bedrock of West Antarctica,&#8230;",
            "tags": [
                "MIT"
            ]
        },
        {
            "title": "Inside a new quest to save the ‚Äúdoomsday glacier‚Äù",
            "source": "MIT Tech Review AI",
            "url": "https://www.technologyreview.com/2025/03/21/1113396/inside-a-new-quest-to-save-the-doomsday-glacier/",
            "published": "Fri, 21 Mar 2025 09:00:00 +0000",
            "summary": "The Thwaites glacier is a fortress larger than Florida, a wall of ice that reaches nearly 4,000 feet above the bedrock of West Antarctica, guarding the low-lying ice sheet behind it. But a strong, warm ocean current is weakening its foundations and accelerating its slide into the Amundsen Sea. Scientists fear the waters could topple&#8230;",
            "tags": [
                "MIT"
            ]
        },
        {
            "title": "Autopsies can reveal intimate health details. Should they be kept private?",
            "source": "MIT Tech Review AI",
            "url": "https://www.technologyreview.com/2025/03/21/1113549/autopsies-reveal-intimate-health-details-kept-private/",
            "published": "Fri, 21 Mar 2025 09:00:00 +0000",
            "summary": "Over the past couple of weeks, I‚Äôve been following news of the deaths of actor Gene Hackman and his wife, pianist Betsy Arakawa. It was heartbreaking to hear how Arakawa appeared to have died from a rare infection days before her husband, who had advanced Alzheimer‚Äôs disease and may have struggled to understand what had&#8230;",
            "tags": [
                "MIT"
            ]
        },
        {
            "title": "R.E.D.: Scaling Text Classification with Expert Delegation",
            "source": "Towards Data Science",
            "url": "https://towardsdatascience.com/r-e-d-scaling-text-classification-with-expert-delegation/",
            "published": "Fri, 21 Mar 2025 05:11:10 +0000",
            "summary": "<p>A novel large-scale semi-supervised framework that augments traditional classification with LLMs</p>\n<p>The post <a href=\"https://towardsdatascience.com/r-e-d-scaling-text-classification-with-expert-delegation/\">R.E.D.: Scaling Text Classification with Expert Delegation</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
            "tags": [
                "TDS"
            ]
        },
        {
            "title": "The New and Fresh analytics in Inference Endpoints",
            "source": "Hugging Face",
            "url": "https://huggingface.co/blog/endpoint-analytics",
            "published": "Fri, 21 Mar 2025 00:00:00 GMT",
            "summary": "No summary available.",
            "tags": [
                "HuggingFace"
            ]
        }
    ]
}